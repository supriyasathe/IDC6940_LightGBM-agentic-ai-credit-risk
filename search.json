[
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature Review",
    "section": "",
    "text": "Five active research pillars form the basis of this project:\n\nCredit Risk Modeling\n\nThe statistical techniques used in early credit risk models, including logistic regression, are interpretable but outperform when applied to complicated, non-linear data. Recent studies have demonstrated that machine learning models, particularly ensemble approaches, greatly increase prediction accuracy. The most advanced models for structured financial data are gradient boosting models like XGBoost and LightGBM. LightGBM provides great speed, scalability, and efficiency for big credit datasets.\n\nExplainable Artificial Intelligence (XAI)\n\nThe black-box character of machine learning models is addressed by explainable AI. By demonstrating how features affect predictions, methods like LIME and SHAP offer both local and global explanations. Because SHAP is theoretically sound and enhances model validation, regulatory compliance, and trust, it is very useful in the finance sector.\n\nInterpretability in Financial Systems\n\nAutomated decision systems must be fair, transparent, and accountable in order to comply with financial requirements. Explainable models are especially important in high-risk fields like credit scoring, where interpretability must be human-centered and adhere to ethical and regulatory norms.\n\nAgentic AI in Decision Systems\n\nBy assessing outputs and suggesting actions, agentic AI systems surpass prediction. Agentic frameworks can combine explanation signals, risk thresholds, and model projections to initiate the proper reactions—approvals, rejections, or manual reviews—in financial decision-making. By verifying that decisions are transparent, flexible, and in line with human oversight, the combination of explainable models with agentic AI allows for responsible automation.\n\nResearch Gap\n\nFew systems combine agentic decision-making, explainability, and predictive modeling into a single framework, despite the widespread use of LightGBM and SHAP. By putting out an Explainable Agentic AI system for credit risk assessment, this project fills this gap."
  },
  {
    "objectID": "literature.html#literature-review",
    "href": "literature.html#literature-review",
    "title": "Literature Review",
    "section": "",
    "text": "Five active research pillars form the basis of this project:\n\nCredit Risk Modeling\n\nThe statistical techniques used in early credit risk models, including logistic regression, are interpretable but outperform when applied to complicated, non-linear data. Recent studies have demonstrated that machine learning models, particularly ensemble approaches, greatly increase prediction accuracy. The most advanced models for structured financial data are gradient boosting models like XGBoost and LightGBM. LightGBM provides great speed, scalability, and efficiency for big credit datasets.\n\nExplainable Artificial Intelligence (XAI)\n\nThe black-box character of machine learning models is addressed by explainable AI. By demonstrating how features affect predictions, methods like LIME and SHAP offer both local and global explanations. Because SHAP is theoretically sound and enhances model validation, regulatory compliance, and trust, it is very useful in the finance sector.\n\nInterpretability in Financial Systems\n\nAutomated decision systems must be fair, transparent, and accountable in order to comply with financial requirements. Explainable models are especially important in high-risk fields like credit scoring, where interpretability must be human-centered and adhere to ethical and regulatory norms.\n\nAgentic AI in Decision Systems\n\nBy assessing outputs and suggesting actions, agentic AI systems surpass prediction. Agentic frameworks can combine explanation signals, risk thresholds, and model projections to initiate the proper reactions—approvals, rejections, or manual reviews—in financial decision-making. By verifying that decisions are transparent, flexible, and in line with human oversight, the combination of explainable models with agentic AI allows for responsible automation.\n\nResearch Gap\n\nFew systems combine agentic decision-making, explainability, and predictive modeling into a single framework, despite the widespread use of LightGBM and SHAP. By putting out an Explainable Agentic AI system for credit risk assessment, this project fills this gap."
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "",
    "text": "A vital role for financial institutions is evaluating credit risk, which has a direct impact on lending choices, portfolio performance, and regulatory compliance. Because they are straightforward and easy to understand, traditional credit scoring techniques like logistic regression have gained widespread use. These conventional models, however, find it difficult to account for nonlinear patterns and complicated borrower behaviors as financial data grows in size, complexity, and heterogeneity.\nThe predictive accuracy of credit risk modeling has greatly increased as a result of recent developments in machine learning, especially ensemble-based techniques like Gradient Boosting Decision Trees (GBDT). Among these techniques, the Light Gradient Boosting Machine (LightGBM) has shown itself to be a very effective and scalable framework that can deal with imbalanced and high-dimensional credit datasets. Although LightGBM performs well, it is frequently perceived as a “black-box” paradigm, which restricts transparency and undermines confidence among auditors, regulators, and business users.\nThis paper suggests an Explainable Agentic AI framework for credit risk assessment utilizing LightGBM in order to overcome these issues. The framework combines an intelligent agentic decision layer that analyzes model predictions, produces insightful explanations, and suggests suitable courses of action with SHAP-based explainability. The suggested approach seeks to facilitate responsible and explicable credit decision-making in regulated financial environments by fusing prediction accuracy, transparency, and adaptive reasoning."
  },
  {
    "objectID": "report.html#introduction",
    "href": "report.html#introduction",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "",
    "text": "A vital role for financial institutions is evaluating credit risk, which has a direct impact on lending choices, portfolio performance, and regulatory compliance. Because they are straightforward and easy to understand, traditional credit scoring techniques like logistic regression have gained widespread use. These conventional models, however, find it difficult to account for nonlinear patterns and complicated borrower behaviors as financial data grows in size, complexity, and heterogeneity.\nThe predictive accuracy of credit risk modeling has greatly increased as a result of recent developments in machine learning, especially ensemble-based techniques like Gradient Boosting Decision Trees (GBDT). Among these techniques, the Light Gradient Boosting Machine (LightGBM) has shown itself to be a very effective and scalable framework that can deal with imbalanced and high-dimensional credit datasets. Although LightGBM performs well, it is frequently perceived as a “black-box” paradigm, which restricts transparency and undermines confidence among auditors, regulators, and business users.\nThis paper suggests an Explainable Agentic AI framework for credit risk assessment utilizing LightGBM in order to overcome these issues. The framework combines an intelligent agentic decision layer that analyzes model predictions, produces insightful explanations, and suggests suitable courses of action with SHAP-based explainability. The suggested approach seeks to facilitate responsible and explicable credit decision-making in regulated financial environments by fusing prediction accuracy, transparency, and adaptive reasoning."
  },
  {
    "objectID": "report.html#methods",
    "href": "report.html#methods",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "2. Methods",
    "text": "2. Methods"
  },
  {
    "objectID": "report.html#analysis-and-results",
    "href": "report.html#analysis-and-results",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "3. Analysis and Results",
    "text": "3. Analysis and Results\n\n3.1 Exploratory Data Analysis (EDA) :\n\n3.1.1 Data Description :\nThe Credit Risk Dataset, which includes 32,581 borrower records and 12 characteristics pertaining to financial, credit history, and demographic data, is used in this study. Binary in nature, the target variable loan_status indicates whether a borrower is likely to default (1) or not (0). Income, loan amount, interest rate, length of employment, home ownership status, and loan purpose are among the numerical and qualitative variables included in the dataset. Its reasonable size and realistic structure make it ideal for using LightGBM and assessing explainable, agentic AI decision-making in credit risk prediction.\n\nDataset Dimensions -\nObservations (rows): 32,581\nFeatures (columns): 12\nTarget Variable: loan_status\n\n\nTarget Variable -\nloan_status\n1 = High Risk (Default)\n0 = Low Risk (Non-Default)\n\n\n\n3.1.2 Data Ingestion (Python) :\nThe pandas package in Python was used to load the dataset. A dataframe called credit1 was created by reading the file credit_risk_dataset.csv. The dataset was first explored by examining column data types, previewing the first few records, and determining its dimensions. To guarantee effective ingestion and comprehend variable composition, the dataset structure was validated using the.shape(),.head(), and.info() functions.\n\n\nCode\nimport os\nimport pandas as pd\n\ndef find_git_root(start=None):\n    if start is None:\n        start = os.getcwd()\n    path = os.path.abspath(start)\n    \n    while True:\n        if os.path.isdir(os.path.join(path, \".git\")):\n            return path\n        \n        parent = os.path.dirname(path)\n        if parent == path:\n            raise FileNotFoundError(\"No .git directory found — are you inside a Git repository?\")\n        \n        path = parent\n\nrepo_root = find_git_root()\ndatasets_path = os.path.join(repo_root, \"datasets\")\n\n# Reading the datafile credit_risk_dataset.csv\ncredit_path = os.path.join(datasets_path, \"credit_risk_dataset.csv\")\ncredit1 = pd.read_csv(credit_path)\n\n\n\n\n3.1.3 Summary Statistics :\n\ncredit1.describe()\n\n         person_age  ...  cb_person_cred_hist_length\ncount  32581.000000  ...                32581.000000\nmean      27.734600  ...                    5.804211\nstd        6.348078  ...                    4.055001\nmin       20.000000  ...                    2.000000\n25%       23.000000  ...                    3.000000\n50%       26.000000  ...                    4.000000\n75%       30.000000  ...                    8.000000\nmax      144.000000  ...                   30.000000\n\n[8 rows x 8 columns]\n\n\nFor a more thorough summary:\n\n\nCode\nfrom skimpy import skim\nskim(credit1)\n\n\n╭─────────────────────────────── skimpy summary ───────────────────────────────╮\n│          Data Summary                Data Types                              │\n│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                       │\n│ ┃ Dataframe         ┃ Values ┃ ┃ Column Type ┃ Count ┃                       │\n│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                       │\n│ │ Number of rows    │ 32581  │ │ int64       │ 5     │                       │\n│ │ Number of columns │ 12     │ │ string      │ 4     │                       │\n│ └───────────────────┴────────┘ │ float64     │ 3     │                       │\n│                                └─────────────┴───────┘                       │\n│                                   number                                     │\n│ ┏━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━┳━━━━━━┳━━━━━┳━━━━━━┳━━━━━┓  │\n│ ┃ colu ┃      ┃      ┃      ┃      ┃      ┃     ┃      ┃     ┃      ┃ his ┃  │\n│ ┃ mn   ┃ NA   ┃ NA % ┃ mean ┃ sd   ┃ p0   ┃ p25 ┃ p50  ┃ p75 ┃ p100 ┃ t   ┃  │\n│ ┡━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━╇━━━━━━╇━━━━━╇━━━━━━╇━━━━━┩  │\n│ │ pers │    0 │    0 │ 27.7 │ 6.34 │   20 │  23 │   26 │  30 │  144 │  █  │  │\n│ │ on_a │      │      │    3 │    8 │      │     │      │     │      │     │  │\n│ │  ge  │      │      │      │      │      │     │      │     │      │     │  │\n│ │ pers │    0 │    0 │ 6607 │ 6198 │ 4000 │ 385 │ 5500 │ 792 │ 6000 │  █  │  │\n│ │ on_i │      │      │    0 │    0 │      │  00 │    0 │  00 │  000 │     │  │\n│ │ ncom │      │      │      │      │      │     │      │     │      │     │  │\n│ │  e   │      │      │      │      │      │     │      │     │      │     │  │\n│ │ pers │  895 │ 2.74 │ 4.79 │ 4.14 │    0 │   2 │    4 │   7 │  123 │  █  │  │\n│ │ on_e │      │ 6999 │      │    3 │      │     │      │     │      │     │  │\n│ │ mp_l │      │ 7851 │      │      │      │     │      │     │      │     │  │\n│ │ engt │      │ 5085 │      │      │      │     │      │     │      │     │  │\n│ │  h   │      │   47 │      │      │      │     │      │     │      │     │  │\n│ │ loan │    0 │    0 │ 9589 │ 6322 │  500 │ 500 │ 8000 │ 122 │ 3500 │ █▇▄ │  │\n│ │ _amn │      │      │      │      │      │   0 │      │  00 │    0 │ ▁▁  │  │\n│ │  t   │      │      │      │      │      │     │      │     │      │     │  │\n│ │ loan │ 3116 │ 9.56 │ 11.0 │ 3.24 │ 5.42 │ 7.9 │ 10.9 │ 13. │ 23.2 │ ▇▇█ │  │\n│ │ _int │      │ 3856 │    1 │      │      │     │    9 │  47 │    2 │ ▄▁  │  │\n│ │ _rat │      │ 2352 │      │      │      │     │      │     │      │     │  │\n│ │  e   │      │ 2912 │      │      │      │     │      │     │      │     │  │\n│ │      │      │    1 │      │      │      │     │      │     │      │     │  │\n│ │ loan │    0 │    0 │ 0.21 │ 0.41 │    0 │   0 │    0 │   0 │    1 │  █  │  │\n│ │ _sta │      │      │   82 │    3 │      │     │      │     │      │  ▂  │  │\n│ │ tus  │      │      │      │      │      │     │      │     │      │     │  │\n│ │ loan │    0 │    0 │ 0.17 │ 0.10 │    0 │ 0.0 │ 0.15 │ 0.2 │ 0.83 │ █▇▂ │  │\n│ │ _per │      │      │   02 │   68 │      │   9 │      │   3 │      │     │  │\n│ │ cent │      │      │      │      │      │     │      │     │      │     │  │\n│ │ _inc │      │      │      │      │      │     │      │     │      │     │  │\n│ │ ome  │      │      │      │      │      │     │      │     │      │     │  │\n│ │ cb_p │    0 │    0 │ 5.80 │ 4.05 │    2 │   3 │    4 │   8 │   30 │ █▃▁ │  │\n│ │ erso │      │      │    4 │    5 │      │     │      │     │      │     │  │\n│ │ n_cr │      │      │      │      │      │     │      │     │      │     │  │\n│ │ ed_h │      │      │      │      │      │     │      │     │      │     │  │\n│ │ ist_ │      │      │      │      │      │     │      │     │      │     │  │\n│ │ leng │      │      │      │      │      │     │      │     │      │     │  │\n│ │  th  │      │      │      │      │      │     │      │     │      │     │  │\n│ └──────┴──────┴──────┴──────┴──────┴──────┴─────┴──────┴─────┴──────┴─────┘  │\n│                                   string                                     │\n│ ┏━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━┓  │\n│ ┃       ┃    ┃      ┃       ┃       ┃       ┃       ┃ char ┃       ┃ tota ┃  │\n│ ┃       ┃    ┃      ┃       ┃       ┃       ┃       ┃ s    ┃ words ┃ l    ┃  │\n│ ┃ colum ┃    ┃      ┃ short ┃ longe ┃       ┃       ┃ per  ┃ per   ┃ word ┃  │\n│ ┃ n     ┃ NA ┃ NA % ┃ est   ┃ st    ┃ min   ┃ max   ┃ row  ┃ row   ┃ s    ┃  │\n│ ┡━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━┩  │\n│ │ perso │  0 │    0 │  OWN  │ MORTG │ MORTG │ RENT  │ 5.57 │     1 │ 3258 │  │\n│ │ n_hom │    │      │       │  AGE  │  AGE  │       │      │       │    1 │  │\n│ │ e_own │    │      │       │       │       │       │      │       │      │  │\n│ │ ershi │    │      │       │       │       │       │      │       │      │  │\n│ │   p   │    │      │       │       │       │       │      │       │      │  │\n│ │ loan_ │  0 │    0 │ MEDIC │ DEBTC │ DEBTC │ VENTU │ 10.1 │     1 │ 3258 │  │\n│ │ inten │    │      │  AL   │ ONSOL │ ONSOL │  RE   │      │       │    1 │  │\n│ │   t   │    │      │       │ IDATI │ IDATI │       │      │       │      │  │\n│ │       │    │      │       │  ON   │  ON   │       │      │       │      │  │\n│ │ loan_ │  0 │    0 │   D   │   D   │   A   │   G   │    1 │     1 │ 3258 │  │\n│ │ grade │    │      │       │       │       │       │      │       │    1 │  │\n│ │ cb_pe │  0 │    0 │   Y   │   Y   │   N   │   Y   │    1 │     1 │ 3258 │  │\n│ │ rson_ │    │      │       │       │       │       │      │       │    1 │  │\n│ │ defau │    │      │       │       │       │       │      │       │      │  │\n│ │ lt_on │    │      │       │       │       │       │      │       │      │  │\n│ │ _file │    │      │       │       │       │       │      │       │      │  │\n│ └───────┴────┴──────┴───────┴───────┴───────┴───────┴──────┴───────┴──────┘  │\n╰──────────────────────────────────── End ─────────────────────────────────────╯\n\n\n\n\n3.1.4 Missing Value Analysis :\n\ncredit1.isna().sum()\n\nperson_age                       0\nperson_income                    0\nperson_home_ownership            0\nperson_emp_length              895\nloan_intent                      0\nloan_grade                       0\nloan_amnt                        0\nloan_int_rate                 3116\nloan_status                      0\nloan_percent_income              0\ncb_person_default_on_file        0\ncb_person_cred_hist_length       0\ndtype: int64\n\n\nperson_emp_length → 895 missing values\nloan_int_rate → 3,116 missing values\nComplete data is present in all other variables.\nPreprocessing will use median imputation to handle these missing values in order to maintain the robustness of the distribution.\n\n\n3.1.5 Target Distribution :\nImport the project dependencies\n\n\n\nCode\npackages &lt;- c(\"tidyverse\", \"skimr\", \"knitr\", \"ggthemes\", \"ggrepel\", \"dslabs\")\n# install.packages(packages)\n# Load Libraries\nlapply(packages, library, character.only = TRUE)\n# Set seed for reproducibility\nset.seed(123)\n\n\n\n\n\n3.1. Data Ingestion\nThis code chunk is importing the dataset from the folder datasets which it is finding at the root of the github repo and it is concatenating the path to run the function read_csv from tidyverse.\n\n\nCode\nfind_git_root &lt;- function(start = getwd()) {\n  path &lt;- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path &lt;- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root &lt;- find_git_root()\ndatasets_path &lt;- file.path(repo_root, \"datasets\")\n\n# Reading the datafile credit_risk_dataset.csv\ncredit_path &lt;- file.path(datasets_path, \"credit_risk_dataset.csv\")\ncredit1 = read_csv(credit_path, show_col_types = FALSE)\n\n\n\nsummary(credit1)\n\n   person_age     person_income     person_home_ownership person_emp_length\n Min.   : 20.00   Min.   :   4000   Length:32581          Min.   :  0.00   \n 1st Qu.: 23.00   1st Qu.:  38500   Class :character      1st Qu.:  2.00   \n Median : 26.00   Median :  55000   Mode  :character      Median :  4.00   \n Mean   : 27.73   Mean   :  66075                         Mean   :  4.79   \n 3rd Qu.: 30.00   3rd Qu.:  79200                         3rd Qu.:  7.00   \n Max.   :144.00   Max.   :6000000                         Max.   :123.00   \n                                                          NA's   :895      \n loan_intent         loan_grade          loan_amnt     loan_int_rate  \n Length:32581       Length:32581       Min.   :  500   Min.   : 5.42  \n Class :character   Class :character   1st Qu.: 5000   1st Qu.: 7.90  \n Mode  :character   Mode  :character   Median : 8000   Median :10.99  \n                                       Mean   : 9589   Mean   :11.01  \n                                       3rd Qu.:12200   3rd Qu.:13.47  \n                                       Max.   :35000   Max.   :23.22  \n                                                       NA's   :3116   \n  loan_status     loan_percent_income cb_person_default_on_file\n Min.   :0.0000   Min.   :0.0000      Length:32581             \n 1st Qu.:0.0000   1st Qu.:0.0900      Class :character         \n Median :0.0000   Median :0.1500      Mode  :character         \n Mean   :0.2182   Mean   :0.1702                               \n 3rd Qu.:0.0000   3rd Qu.:0.2300                               \n Max.   :1.0000   Max.   :0.8300                               \n                                                               \n cb_person_cred_hist_length\n Min.   : 2.000            \n 1st Qu.: 3.000            \n Median : 4.000            \n Mean   : 5.804            \n 3rd Qu.: 8.000            \n Max.   :30.000            \n                           \n\nhead(credit1)\n\n# A tibble: 6 × 12\n  person_age person_income person_home_ownership person_emp_length loan_intent\n       &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt; &lt;chr&gt;      \n1         22         59000 RENT                                123 PERSONAL   \n2         21          9600 OWN                                   5 EDUCATION  \n3         25          9600 MORTGAGE                              1 MEDICAL    \n4         23         65500 RENT                                  4 MEDICAL    \n5         24         54400 RENT                                  8 MEDICAL    \n6         21          9900 OWN                                   2 VENTURE    \n# ℹ 7 more variables: loan_grade &lt;chr&gt;, loan_amnt &lt;dbl&gt;, loan_int_rate &lt;dbl&gt;,\n#   loan_status &lt;dbl&gt;, loan_percent_income &lt;dbl&gt;,\n#   cb_person_default_on_file &lt;chr&gt;, cb_person_cred_hist_length &lt;dbl&gt;\n\n# Count total NAs per column\ncolSums(is.na(credit1))\n\n                person_age              person_income \n                         0                          0 \n     person_home_ownership          person_emp_length \n                         0                        895 \n               loan_intent                 loan_grade \n                         0                          0 \n                 loan_amnt              loan_int_rate \n                         0                       3116 \n               loan_status        loan_percent_income \n                         0                          0 \n cb_person_default_on_file cb_person_cred_hist_length \n                         0                          0 \n\n\nwe found that:\n\nperson_emp_length has 895 NA values\nloan_int_rate has 3116 NA values\n\ntest data ingestion using python\n\n# renv::use_python(type = \"conda\", envname = \"myenv\")\n# reticulate::py_install(\"numpy\")\n# reticulate::py_install(\"pandas\")\n# reticulate::py_install(\"skimpy\")\n\n\n# pip install pandas numpy\n\n\n\nCode\nimport os\nimport pandas as pd\n\ndef find_git_root(start=None):\n    if start is None:\n        start = os.getcwd()\n    path = os.path.abspath(start)\n    \n    while True:\n        if os.path.isdir(os.path.join(path, \".git\")):\n            return path\n        \n        parent = os.path.dirname(path)\n        if parent == path:\n            raise FileNotFoundError(\"No .git directory found — are you inside a Git repository?\")\n        \n        path = parent\n\nrepo_root = find_git_root()\ndatasets_path = os.path.join(repo_root, \"datasets\")\n\n# Reading the datafile credit_risk_dataset.csv\ncredit_path = os.path.join(datasets_path, \"credit_risk_dataset.csv\")\ncredit1 = pd.read_csv(credit_path)\n\n\n\nfrom skimpy import skim\n\nskim(credit1)\n\n╭─────────────────────────────── skimpy summary ───────────────────────────────╮\n│          Data Summary                Data Types                              │\n│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                       │\n│ ┃ Dataframe         ┃ Values ┃ ┃ Column Type ┃ Count ┃                       │\n│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                       │\n│ │ Number of rows    │ 32581  │ │ int64       │ 5     │                       │\n│ │ Number of columns │ 12     │ │ string      │ 4     │                       │\n│ └───────────────────┴────────┘ │ float64     │ 3     │                       │\n│                                └─────────────┴───────┘                       │\n│                                   number                                     │\n│ ┏━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━┳━━━━━━┳━━━━━┳━━━━━━┳━━━━━┓  │\n│ ┃ colu ┃      ┃      ┃      ┃      ┃      ┃     ┃      ┃     ┃      ┃ his ┃  │\n│ ┃ mn   ┃ NA   ┃ NA % ┃ mean ┃ sd   ┃ p0   ┃ p25 ┃ p50  ┃ p75 ┃ p100 ┃ t   ┃  │\n│ ┡━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━╇━━━━━━╇━━━━━╇━━━━━━╇━━━━━┩  │\n│ │ pers │    0 │    0 │ 27.7 │ 6.34 │   20 │  23 │   26 │  30 │  144 │  █  │  │\n│ │ on_a │      │      │    3 │    8 │      │     │      │     │      │     │  │\n│ │  ge  │      │      │      │      │      │     │      │     │      │     │  │\n│ │ pers │    0 │    0 │ 6607 │ 6198 │ 4000 │ 385 │ 5500 │ 792 │ 6000 │  █  │  │\n│ │ on_i │      │      │    0 │    0 │      │  00 │    0 │  00 │  000 │     │  │\n│ │ ncom │      │      │      │      │      │     │      │     │      │     │  │\n│ │  e   │      │      │      │      │      │     │      │     │      │     │  │\n│ │ pers │  895 │ 2.74 │ 4.79 │ 4.14 │    0 │   2 │    4 │   7 │  123 │  █  │  │\n│ │ on_e │      │ 6999 │      │    3 │      │     │      │     │      │     │  │\n│ │ mp_l │      │ 7851 │      │      │      │     │      │     │      │     │  │\n│ │ engt │      │ 5085 │      │      │      │     │      │     │      │     │  │\n│ │  h   │      │   47 │      │      │      │     │      │     │      │     │  │\n│ │ loan │    0 │    0 │ 9589 │ 6322 │  500 │ 500 │ 8000 │ 122 │ 3500 │ █▇▄ │  │\n│ │ _amn │      │      │      │      │      │   0 │      │  00 │    0 │ ▁▁  │  │\n│ │  t   │      │      │      │      │      │     │      │     │      │     │  │\n│ │ loan │ 3116 │ 9.56 │ 11.0 │ 3.24 │ 5.42 │ 7.9 │ 10.9 │ 13. │ 23.2 │ ▇▇█ │  │\n│ │ _int │      │ 3856 │    1 │      │      │     │    9 │  47 │    2 │ ▄▁  │  │\n│ │ _rat │      │ 2352 │      │      │      │     │      │     │      │     │  │\n│ │  e   │      │ 2912 │      │      │      │     │      │     │      │     │  │\n│ │      │      │    1 │      │      │      │     │      │     │      │     │  │\n│ │ loan │    0 │    0 │ 0.21 │ 0.41 │    0 │   0 │    0 │   0 │    1 │  █  │  │\n│ │ _sta │      │      │   82 │    3 │      │     │      │     │      │  ▂  │  │\n│ │ tus  │      │      │      │      │      │     │      │     │      │     │  │\n│ │ loan │    0 │    0 │ 0.17 │ 0.10 │    0 │ 0.0 │ 0.15 │ 0.2 │ 0.83 │ █▇▂ │  │\n│ │ _per │      │      │   02 │   68 │      │   9 │      │   3 │      │     │  │\n│ │ cent │      │      │      │      │      │     │      │     │      │     │  │\n│ │ _inc │      │      │      │      │      │     │      │     │      │     │  │\n│ │ ome  │      │      │      │      │      │     │      │     │      │     │  │\n│ │ cb_p │    0 │    0 │ 5.80 │ 4.05 │    2 │   3 │    4 │   8 │   30 │ █▃▁ │  │\n│ │ erso │      │      │    4 │    5 │      │     │      │     │      │     │  │\n│ │ n_cr │      │      │      │      │      │     │      │     │      │     │  │\n│ │ ed_h │      │      │      │      │      │     │      │     │      │     │  │\n│ │ ist_ │      │      │      │      │      │     │      │     │      │     │  │\n│ │ leng │      │      │      │      │      │     │      │     │      │     │  │\n│ │  th  │      │      │      │      │      │     │      │     │      │     │  │\n│ └──────┴──────┴──────┴──────┴──────┴──────┴─────┴──────┴─────┴──────┴─────┘  │\n│                                   string                                     │\n│ ┏━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━┓  │\n│ ┃       ┃    ┃      ┃       ┃       ┃       ┃       ┃ char ┃       ┃ tota ┃  │\n│ ┃       ┃    ┃      ┃       ┃       ┃       ┃       ┃ s    ┃ words ┃ l    ┃  │\n│ ┃ colum ┃    ┃      ┃ short ┃ longe ┃       ┃       ┃ per  ┃ per   ┃ word ┃  │\n│ ┃ n     ┃ NA ┃ NA % ┃ est   ┃ st    ┃ min   ┃ max   ┃ row  ┃ row   ┃ s    ┃  │\n│ ┡━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━┩  │\n│ │ perso │  0 │    0 │  OWN  │ MORTG │ MORTG │ RENT  │ 5.57 │     1 │ 3258 │  │\n│ │ n_hom │    │      │       │  AGE  │  AGE  │       │      │       │    1 │  │\n│ │ e_own │    │      │       │       │       │       │      │       │      │  │\n│ │ ershi │    │      │       │       │       │       │      │       │      │  │\n│ │   p   │    │      │       │       │       │       │      │       │      │  │\n│ │ loan_ │  0 │    0 │ MEDIC │ DEBTC │ DEBTC │ VENTU │ 10.1 │     1 │ 3258 │  │\n│ │ inten │    │      │  AL   │ ONSOL │ ONSOL │  RE   │      │       │    1 │  │\n│ │   t   │    │      │       │ IDATI │ IDATI │       │      │       │      │  │\n│ │       │    │      │       │  ON   │  ON   │       │      │       │      │  │\n│ │ loan_ │  0 │    0 │   D   │   D   │   A   │   G   │    1 │     1 │ 3258 │  │\n│ │ grade │    │      │       │       │       │       │      │       │    1 │  │\n│ │ cb_pe │  0 │    0 │   Y   │   Y   │   N   │   Y   │    1 │     1 │ 3258 │  │\n│ │ rson_ │    │      │       │       │       │       │      │       │    1 │  │\n│ │ defau │    │      │       │       │       │       │      │       │      │  │\n│ │ lt_on │    │      │       │       │       │       │      │       │      │  │\n│ │ _file │    │      │       │       │       │       │      │       │      │  │\n│ └───────┴────┴──────┴───────┴───────┴───────┴───────┴──────┴───────┴──────┘  │\n╰──────────────────────────────────── End ─────────────────────────────────────╯\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "report.html#conclusion",
    "href": "report.html#conclusion",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "4. Conclusion",
    "text": "4. Conclusion\n\n\nReferences"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "",
    "text": "A vital role for financial institutions is evaluating credit risk, which has a direct impact on lending choices, portfolio performance, and regulatory compliance. Because they are straightforward and easy to understand, traditional credit scoring techniques like logistic regression have gained widespread use. These conventional models, however, find it difficult to account for nonlinear patterns and complicated borrower behaviors as financial data grows in size, complexity, and heterogeneity.\nThe predictive accuracy of credit risk modeling has greatly increased as a result of recent developments in machine learning, especially ensemble-based techniques like Gradient Boosting Decision Trees (GBDT). Among these techniques, the Light Gradient Boosting Machine (LightGBM) has shown itself to be a very effective and scalable framework that can deal with imbalanced and high-dimensional credit datasets. Although LightGBM performs well, it is frequently perceived as a “black-box” paradigm, which restricts transparency and undermines confidence among auditors, regulators, and business users.\nThis paper suggests an Explainable Agentic AI framework for credit risk assessment utilizing LightGBM in order to overcome these issues. The framework combines an intelligent agentic decision layer that analyzes model predictions, produces insightful explanations, and suggests suitable courses of action with SHAP-based explainability. The suggested approach seeks to facilitate responsible and explicable credit decision-making in regulated financial environments by fusing prediction accuracy, transparency, and adaptive reasoning."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "",
    "text": "A vital role for financial institutions is evaluating credit risk, which has a direct impact on lending choices, portfolio performance, and regulatory compliance. Because they are straightforward and easy to understand, traditional credit scoring techniques like logistic regression have gained widespread use. These conventional models, however, find it difficult to account for nonlinear patterns and complicated borrower behaviors as financial data grows in size, complexity, and heterogeneity.\nThe predictive accuracy of credit risk modeling has greatly increased as a result of recent developments in machine learning, especially ensemble-based techniques like Gradient Boosting Decision Trees (GBDT). Among these techniques, the Light Gradient Boosting Machine (LightGBM) has shown itself to be a very effective and scalable framework that can deal with imbalanced and high-dimensional credit datasets. Although LightGBM performs well, it is frequently perceived as a “black-box” paradigm, which restricts transparency and undermines confidence among auditors, regulators, and business users.\nThis paper suggests an Explainable Agentic AI framework for credit risk assessment utilizing LightGBM in order to overcome these issues. The framework combines an intelligent agentic decision layer that analyzes model predictions, produces insightful explanations, and suggests suitable courses of action with SHAP-based explainability. The suggested approach seeks to facilitate responsible and explicable credit decision-making in regulated financial environments by fusing prediction accuracy, transparency, and adaptive reasoning."
  },
  {
    "objectID": "index.html#cheatsheet",
    "href": "index.html#cheatsheet",
    "title": "Explainable Agentic AI for Credit Risk Assessment using LightGBM",
    "section": "Cheatsheet",
    "text": "Cheatsheet\nThis project is focused on experimenting with the code chunks to ingest and analyse the dataset as a preliminary analysis.\nFor the project remember to add the appropriate flags into the code chunks otherwise everything will be rendered.\nBelow are example of flags for the code chunk also a code chunk with double curly brackest is not executable {{r}}:\n```{r}\n#| code-fold: true\n#| message: false\n#| warning: false\n#| output: false\n```\nNOTE:\nthese shorcuts are helpfull when debugging or testing code chunks\n\nCtrl + Enter (Windows/Linux) or Cmd + Enter (Mac) will execute the current line the cursor is on.\nShift + Enter (Windows/Linux and Mac) will execute the currently highlighted multiple lines of code."
  },
  {
    "objectID": "slides.html#introduction",
    "href": "slides.html#introduction",
    "title": "Present a great story for data science projects",
    "section": "Introduction",
    "text": "Introduction\nIn financial institutions, evaluating credit risk is essential since it has a direct bearing on lending choices, portfolio performance, and regulatory compliance. The simplicity and interpretability of traditional credit scoring models, including logistic regression, have led to their widespread use. Unfortunately, these models are less successful due to the increasing number and complexity of financial data, as they are unable to capture complicated borrower behavior and non-linear correlations. Credit risk prediction has been greatly enhanced by recent developments in machine learning, particularly ensemble techniques like Gradient Boosting Decision Trees. Large, high-dimensional, and unbalanced credit datasets can be handled using the scalable and potent Light Gradient Boosting Machine (LightGBM) model. LightGBM is frequently regarded as a black-box approach, which restricts transparency and erodes confidence among regulators and business users despite its impressive performance. This study suggests an Explainable Agentic AI framework for credit risk assessment utilizing LightGBM in order to overcome these issues. An intelligent agentic decision layer that can read predictions, produce explanations, and suggest actions is combined with LightGBM and SHAP-based explainability. The system seeks to promote responsible and explicable credit judgments in regulated financial contexts by combining accuracy, transparency, and adaptive decision-making."
  },
  {
    "objectID": "slides.html#methods",
    "href": "slides.html#methods",
    "title": "Present a great story for data science projects",
    "section": "Methods",
    "text": "Methods\n\nDetail the models or algorithms used.\nJustify your choices based on the problem and data."
  },
  {
    "objectID": "slides.html#data-exploration-and-visualization",
    "href": "slides.html#data-exploration-and-visualization",
    "title": "Present a great story for data science projects",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization\n\nDescribe your data sources and collection process.\nPresent initial findings and insights through visualizations.\nHighlight unexpected patterns or anomalies."
  },
  {
    "objectID": "slides.html#data-exploration-and-visualization-1",
    "href": "slides.html#data-exploration-and-visualization-1",
    "title": "Present a great story for data science projects",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization\nA study was conducted to determine how…"
  },
  {
    "objectID": "slides.html#modeling-and-results",
    "href": "slides.html#modeling-and-results",
    "title": "Present a great story for data science projects",
    "section": "Modeling and Results",
    "text": "Modeling and Results\n\nExplain your data preprocessing and cleaning steps.\nPresent your key findings in a clear and concise manner.\nUse visuals to support your claims.\nTell a story about what the data reveals."
  },
  {
    "objectID": "slides.html#conclusion",
    "href": "slides.html#conclusion",
    "title": "Present a great story for data science projects",
    "section": "Conclusion",
    "text": "Conclusion\n\nSummarize your key findings.\nDiscuss the implications of your results."
  },
  {
    "objectID": "slides.html#references",
    "href": "slides.html#references",
    "title": "Present a great story for data science projects",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Running code chunks",
    "section": "",
    "text": "Code\nprint(\"hello world!\")\n\n\n[1] \"hello world!\"\n\n\n\n\nCode\n# install.packages(\"reticulate\")\n\n\nthis command is used in R in the context of renv to install python packages\n\n\nCode\n# renv::use_python(type = \"conda\", envname = \"myenv\")\n# reticulate::py_install(\"matplotlib\")\n# reticulate::py_install(\"pandas\")\n\n\n```{text}\nThe downloaded binary packages are in\n        /var/folders/zr/rsp_30h14f16x29fb79jtv_40000gn/T//RtmpIujSpc/downloaded_packages\nWarning message:\nIn doTryCatch(return(expr), name, parentenv, handler) :\n  unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n  Referenced from: &lt;7ECC4104-EC6A-38FD-9BEA-BFE0B870925C&gt; /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/modules/R_X11.so\n  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/Library/Frameworks/R.framework/Resources/lib/libSM.6.dylib' (no such file), '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libSM.6.dylib' (no such file)\n```"
  },
  {
    "objectID": "test.html#r-code-chunks",
    "href": "test.html#r-code-chunks",
    "title": "Running code chunks",
    "section": "",
    "text": "Code\nprint(\"hello world!\")\n\n\n[1] \"hello world!\"\n\n\n\n\nCode\n# install.packages(\"reticulate\")\n\n\nthis command is used in R in the context of renv to install python packages\n\n\nCode\n# renv::use_python(type = \"conda\", envname = \"myenv\")\n# reticulate::py_install(\"matplotlib\")\n# reticulate::py_install(\"pandas\")\n\n\n```{text}\nThe downloaded binary packages are in\n        /var/folders/zr/rsp_30h14f16x29fb79jtv_40000gn/T//RtmpIujSpc/downloaded_packages\nWarning message:\nIn doTryCatch(return(expr), name, parentenv, handler) :\n  unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n  Referenced from: &lt;7ECC4104-EC6A-38FD-9BEA-BFE0B870925C&gt; /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/modules/R_X11.so\n  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/Library/Frameworks/R.framework/Resources/lib/libSM.6.dylib' (no such file), '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libSM.6.dylib' (no such file)\n```"
  },
  {
    "objectID": "test.html#python-code-chunks",
    "href": "test.html#python-code-chunks",
    "title": "Running code chunks",
    "section": "Python code chunks",
    "text": "Python code chunks\n\n\nCode\n# library(reticulate)\n# /opt/anaconda3/bin/python\n# /usr/local/bin/python\n# use_python(\"/opt/anaconda3/bin/python\")\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\n\n\nCode\nimport os\nimport pandas as pd\n\ndef find_git_root(start=None):\n    if start is None:\n        start = os.getcwd()\n    path = os.path.abspath(start)\n    \n    while True:\n        if os.path.isdir(os.path.join(path, \".git\")):\n            return path\n        \n        parent = os.path.dirname(path)\n        if parent == path:\n            raise FileNotFoundError(\"No .git directory found — are you inside a Git repository?\")\n        \n        path = parent\n\nrepo_root = find_git_root()\ndatasets_path = os.path.join(repo_root, \"datasets\")\n\n# Reading the datafile credit_risk_dataset.csv\ncredit_path = os.path.join(datasets_path, \"credit_risk_dataset.csv\")\ncredit1 = pd.read_csv(credit_path)"
  }
]