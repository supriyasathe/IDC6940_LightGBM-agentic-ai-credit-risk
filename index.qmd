---
title: "Explainable Agentic AI for Credit Risk Assessment using LightGBM"
# subtitle: ""
author: "Supriya Sathe (Advisor: Dr. Cohen)"
date: '02 / 11 / 2026'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

In financial institutions, evaluating credit risk is essential since it has a direct bearing on lending choices, portfolio performance, and regulatory compliance. The simplicity and interpretability of traditional credit scoring models, including logistic regression, have led to their widespread use. Unfortunately, these models are less successful due to the increasing number and complexity of financial data, as they are unable to capture complicated borrower behavior and non-linear correlations. 

Credit risk prediction has been greatly enhanced by recent developments in machine learning, particularly ensemble techniques like Gradient Boosting Decision Trees. Large, high-dimensional, and unbalanced credit datasets can be handled using the scalable and potent Light Gradient Boosting Machine (LightGBM) model. LightGBM is frequently regarded as a black-box approach, which restricts transparency and erodes confidence among regulators and business users despite its impressive performance.

This study suggests an Explainable Agentic AI framework for credit risk assessment utilizing LightGBM in order to overcome these issues. An intelligent agentic decision layer that can read predictions, produce explanations, and suggest actions is combined with LightGBM and SHAP-based explainability. The system seeks to promote responsible and explicable credit judgments in regulated financial contexts by combining accuracy, transparency, and adaptive decision-making.

---

## Literature Review

Three active research pillars form the basis of this project:

1. Credit Risk Modeling 
The statistical techniques used in early credit risk models, including logistic regression, are interpretable but outperform when applied to complicated, non-linear data. Recent studies have demonstrated that machine learning models, particularly ensemble approaches, greatly increase prediction accuracy. The most advanced models for structured financial data are gradient boosting models like XGBoost and LightGBM. LightGBM provides great speed, scalability, and efficiency for big credit datasets.

2. Explainable Artificial Intelligence (XAI) 
The black-box character of machine learning models is addressed by explainable AI. By demonstrating how features affect predictions, methods like LIME and SHAP offer both local and global explanations. Because SHAP is theoretically sound and enhances model validation, regulatory compliance, and trust, it is very useful in the finance sector.

3. Interpretability in Financial Systems
Automated decision systems must be fair, transparent, and accountable in order to comply with financial requirements. Explainable models are especially important in high-risk fields like credit scoring, where interpretability must be human-centered and adhere to ethical and regulatory norms.

4. Agentic AI in Decision Systems
By assessing outputs and suggesting actions, agentic AI systems surpass prediction. Agentic frameworks can combine explanation signals, risk thresholds, and model projections to initiate the proper reactions—approvals, rejections, or manual reviews—in financial decision-making.

By verifying that decisions are transparent, flexible, and in line with human oversight, the combination of explainable models with agentic AI allows for responsible automation.

5. Research Gap
Few systems combine agentic decision-making, explainability, and predictive modeling into a single framework, despite the widespread use of LightGBM and SHAP. By putting out an Explainable Agentic AI system for credit risk assessment, this project fills this gap.
